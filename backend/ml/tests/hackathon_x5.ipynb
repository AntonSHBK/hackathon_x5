{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce5d94a",
   "metadata": {},
   "source": [
    "# X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "837ebf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36e0b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed2f6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('../../../data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_DOWNLOAD = DATA_PATH / Path('download/')\n",
    "DATA_PATH_DOWNLOAD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_DATASET = DATA_PATH / Path('datasets/')\n",
    "DATA_PATH_DATASET.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = DATA_PATH / Path('cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = DATA_PATH / Path('models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_IMGS = DATA_PATH /  Path('imgs/')\n",
    "DATA_IMGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7fcec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db7ff8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_MODEL_NAME = 'cointegrated/rubert-tiny2'\n",
    "MODEL_NAME_SAVE = \"ner_x5\"\n",
    "MODEL_CHECKPOINT_PATH = \"ner_x5_checkpoint\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66775d5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "\n",
    "current_date = datetime.now().strftime(\"%d-%m-%Y\")\n",
    "DATA_LOG = DATA_PATH / Path(f'../log/{MODEL_NAME_SAVE}_{current_date}')\n",
    "DATA_LOG.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7fed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "BATCH_SIZE = 16"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a008b155",
   "metadata": {},
   "source": [
    "# –î–∞–Ω–Ω—ã–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db66fba",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x5 = pd.read_csv(DATA_PATH_DATASET / \"train.csv\", sep=\";\")\n",
    "\n",
    "df_x5.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f19774fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_annotations(ann_list):\n",
    "    if isinstance(ann_list, str):\n",
    "        ann_list = eval(ann_list)\n",
    "    new_list = []\n",
    "    for start, end, label in ann_list:\n",
    "        if label == \"0\":\n",
    "            label = \"O\"\n",
    "        new_list.append((start, end, label))\n",
    "    return new_list\n",
    "\n",
    "df_x5[\"annotation\"] = df_x5[\"annotation\"].apply(normalize_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0514259",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels = set()\n",
    "\n",
    "for ann_list in df_x5[\"annotation\"]:\n",
    "    if isinstance(ann_list, str):\n",
    "        ann_list = eval(ann_list)\n",
    "    for _, _, label in ann_list:\n",
    "        all_labels.add(label)\n",
    "\n",
    "unique_labels = sorted(all_labels)\n",
    "unique_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27c13579",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_x5.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fe5c506",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = pd.concat([df_x5], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b11f7180",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "362e3993",
   "metadata": {},
   "source": [
    "# –°–ª–æ–≤–∞—Ä–∏"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97c21ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_labels = {label for anns in df_train[\"annotation\"] for _, _, label in anns if label != \"O\"}\n",
    "\n",
    "b_labels = sorted([lbl for lbl in unique_labels if lbl.startswith(\"B-\")])\n",
    "i_labels = {lbl[2:]: lbl for lbl in unique_labels if lbl.startswith(\"I-\")}\n",
    "\n",
    "all_labels = [\"O\"]\n",
    "for b in b_labels:\n",
    "    all_labels.append(b)\n",
    "    base = b[2:]\n",
    "    if base in i_labels:\n",
    "        all_labels.append(i_labels[base])\n",
    "\n",
    "label2idx = {label: idx for idx, label in enumerate(all_labels)}\n",
    "idx2label = {idx: label for label, idx in label2idx.items()}\n",
    "\n",
    "print(\"label2idx:\", label2idx)\n",
    "print(\"idx2label:\", idx2label)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c72237",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "label2idx_path = DATA_PATH_SAVE_MODELS / \"label2idx.json\"\n",
    "idx2label_path = DATA_PATH_SAVE_MODELS / \"idx2label.json\"\n",
    "\n",
    "with open(label2idx_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(label2idx, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "with open(idx2label_path, \"w\", encoding=\"utf-8\") as f:\n",
    "    json.dump(idx2label, f, ensure_ascii=False, indent=4)\n",
    "\n",
    "print(f\"–°–ª–æ–≤–∞—Ä—å label2idx —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {label2idx_path}\")\n",
    "print(f\"–°–ª–æ–≤–∞—Ä—å idx2label —Å–æ—Ö—Ä–∞–Ω—ë–Ω –≤ {idx2label_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "24937c75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efad2c54",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "d56d0c1a",
   "metadata": {},
   "source": [
    "# –î–∞—Ç–∞—Å–µ—Ç"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3dc707e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_data: pd.DataFrame\n",
    "test_data: pd.DataFrame\n",
    "train_data, test_data = train_test_split(\n",
    "    df_train,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n",
    "\n",
    "val_data: pd.DataFrame\n",
    "train_data, val_data = train_test_split(\n",
    "    train_data,\n",
    "    test_size=0.1,\n",
    "    shuffle=True,\n",
    "    random_state=42,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2edea836",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "\n",
    "from tqdm import tqdm\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import Dataset\n",
    "from transformers import AutoTokenizer, DebertaV2Tokenizer\n",
    "from typing import Tuple, Dict, Optional\n",
    "\n",
    "\n",
    "class NerDataSet(Dataset):\n",
    "    def __init__(\n",
    "        self, df: pd.DataFrame, \n",
    "        max_length: int, \n",
    "        tokenizer_path: str, \n",
    "        label2idx: Dict[str, int],\n",
    "        cache_dir: str = None, \n",
    "        text_label: str = 'sample',\n",
    "        target_label: str = 'annotation',        \n",
    "        dtype_input_ids: torch.dtype = torch.long,\n",
    "        dtype_token_type_ids: torch.dtype = torch.long,\n",
    "        dtype_attention_mask: torch.dtype = torch.long,\n",
    "        dtype_labels : torch.dtype = torch.long,\n",
    "        debug: bool = False,\n",
    "    ):\n",
    "        self.df = df.copy().reset_index(drop=True)\n",
    "        self.max_length = max_length\n",
    "        self.text_label = text_label\n",
    "        self.target_label = target_label\n",
    "        self.debug = debug\n",
    "        \n",
    "        self.label2idx = label2idx\n",
    "        \n",
    "        # TODO –¥–æ–±–∞–≤–∏—Ç—å –∫–ª–∞—Å—Å –¥–ª—è —Ç–∏–ø–∏–∑–∞—Ü–∏–∏\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
    "            tokenizer_path,\n",
    "            cache_dir=cache_dir,\n",
    "            use_fast=True,\n",
    "        )\n",
    "\n",
    "        self.dtype_input_ids = dtype_input_ids\n",
    "        self.dtype_token_type_ids = dtype_token_type_ids\n",
    "        self.dtype_attention_mask = dtype_attention_mask\n",
    "        self.dtype_labels  = dtype_labels \n",
    "\n",
    "        self.input_ids, self.token_type_ids, self.attention_mask, self.labels = self.tokenize_data()\n",
    "\n",
    "    def tokenize_data(self):\n",
    "        input_ids, token_type_ids, attention_mask, labels = [], [], [], []\n",
    "        tokens_ids_debug, tokens_text_debug, labels_debug = [], [], []\n",
    "\n",
    "        for _, row in tqdm(\n",
    "            self.df.iterrows(),\n",
    "            total=len(self.df),\n",
    "            desc=\"Tokenizing data\",\n",
    "            ncols=100\n",
    "        ):\n",
    "            text = row[self.text_label]\n",
    "            ann_list = row[self.target_label]\n",
    "\n",
    "            if isinstance(ann_list, str):\n",
    "                ann_list = eval(ann_list)\n",
    "\n",
    "            encoded = self.tokenizer(\n",
    "                text,\n",
    "                max_length=self.max_length,\n",
    "                padding=\"max_length\",\n",
    "                truncation=True,\n",
    "                return_offsets_mapping=True,\n",
    "                return_token_type_ids=True,\n",
    "            )\n",
    "\n",
    "            offsets = encoded[\"offset_mapping\"]\n",
    "            seq_labels = [\"O\"] * len(offsets)\n",
    "\n",
    "            for start, end, ent_label in ann_list:\n",
    "                inside = False\n",
    "                for i, (tok_start, tok_end) in enumerate(offsets):\n",
    "                    if tok_start >= end:\n",
    "                        break\n",
    "                    if tok_end <= start:\n",
    "                        continue\n",
    "\n",
    "                    if not inside:\n",
    "                        seq_labels[i] = ent_label  # B-XXX\n",
    "                        inside = True\n",
    "                    else:\n",
    "                        # –ø—Ä–µ–æ–±—Ä–∞–∑—É–µ–º \"B-XXX\" ‚Üí \"I-XXX\"\n",
    "                        if ent_label.startswith(\"B-\"):\n",
    "                            seq_labels[i] = \"I-\" + ent_label.split(\"-\", 1)[1]\n",
    "                        else:\n",
    "                            seq_labels[i] = ent_label\n",
    "\n",
    "            # –∫–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è –≤ –∏–Ω–¥–µ–∫—Å—ã\n",
    "            label_ids = []\n",
    "            for i, label in enumerate(seq_labels):\n",
    "                if encoded[\"attention_mask\"][i] == 0:\n",
    "                    label_ids.append(-100)\n",
    "                else:\n",
    "                    label_ids.append(self.label2idx.get(label, self.label2idx[\"O\"]))\n",
    "\n",
    "            # –¥–æ–±–∞–≤–ª—è–µ–º –≤ –º–∞—Å—Å–∏–≤—ã\n",
    "            input_ids.append(torch.tensor(encoded[\"input_ids\"], dtype=self.dtype_input_ids))\n",
    "            token_type_ids.append(torch.tensor(encoded.get(\"token_type_ids\", [0]*len(label_ids)), dtype=self.dtype_token_type_ids))\n",
    "            attention_mask.append(torch.tensor(encoded[\"attention_mask\"], dtype=self.dtype_attention_mask))\n",
    "            labels.append(torch.tensor(label_ids, dtype=self.dtype_labels))\n",
    "\n",
    "            if self.debug:\n",
    "                tokens_ids_debug.append(encoded[\"input_ids\"])\n",
    "                tokens_text_debug.append(self.tokenizer.convert_ids_to_tokens(encoded[\"input_ids\"]))\n",
    "                labels_debug.append(seq_labels)\n",
    "\n",
    "        input_ids = torch.stack(input_ids)\n",
    "        token_type_ids = torch.stack(token_type_ids)\n",
    "        attention_mask = torch.stack(attention_mask)\n",
    "        labels = torch.stack(labels)\n",
    "\n",
    "        if self.debug:\n",
    "            self.df[\"tokens_ids_debug\"] = tokens_ids_debug\n",
    "            self.df[\"tokens_text_debug\"] = tokens_text_debug\n",
    "            self.df[\"labels_debug\"] = labels_debug\n",
    "\n",
    "        return input_ids, token_type_ids, attention_mask, labels\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:\n",
    "        return {\n",
    "            \"input_ids\": self.input_ids[idx],\n",
    "            \"attention_mask\": self.attention_mask[idx],\n",
    "            \"token_type_ids\": self.token_type_ids[idx],\n",
    "            \"labels\": self.labels[idx],\n",
    "        }\n",
    "        \n",
    "    def plot_token_length_distribution(self):\n",
    "        \"\"\"\n",
    "        –°—Ç—Ä–æ–∏—Ç –≥–∏—Å—Ç–æ–≥—Ä–∞–º–º—É —Ä–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏—è –¥–ª–∏–Ω—ã —Ç–æ–∫–µ–Ω–æ–≤ (–±–µ–∑ —Å–ø–µ—Ü–∏–∞–ª—å–Ω—ã—Ö —Ç–æ–∫–µ–Ω–æ–≤ –∏ –ø–∞–¥–¥–∏–Ω–≥–∞).\n",
    "        –†–∞–±–æ—Ç–∞–µ—Ç —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –∫–ª–∞—Å—Å –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∏—Ä–æ–≤–∞–Ω —Å debug=True.\n",
    "        \"\"\"\n",
    "        if not self.debug:\n",
    "            raise ValueError(\"–î–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º–æ –≤–∫–ª—é—á–∏—Ç—å debug=True –ø—Ä–∏ –∏–Ω–∏—Ü–∏–∞–ª–∏–∑–∞—Ü–∏–∏.\")\n",
    "\n",
    "        token_lengths = []\n",
    "        special_ids = set(self.tokenizer.all_special_ids)\n",
    "\n",
    "        for token_ids in self.df[\"tokens_ids_debug\"]:\n",
    "            filtered_tokens = [tid for tid in token_ids if tid not in special_ids]\n",
    "            token_lengths.append(len(filtered_tokens))\n",
    "\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        plt.hist(token_lengths, bins=30, alpha=0.7, edgecolor=\"black\")\n",
    "        plt.xlabel(\"–î–ª–∏–Ω–∞ —Ç–µ–∫—Å—Ç–∞ (–∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Ç–æ–∫–µ–Ω–æ–≤)\")\n",
    "        plt.ylabel(\"–ß–∞—Å—Ç–æ—Ç–∞\")\n",
    "        plt.title(\"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ –¥–ª–∏–Ω —Ç–µ–∫—Å—Ç–æ–≤ –≤ —Ç–æ–∫–µ–Ω–∞—Ö\")\n",
    "        plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.7)\n",
    "        plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0bd1735e",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f03690b",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtype_input = torch.long\n",
    "dtype_labels = torch.long\n",
    "\n",
    "train_dataset = NerDataSet(\n",
    "    df=train_data, \n",
    "    max_length=MAX_LENGTH, \n",
    "    tokenizer_path=BASE_MODEL_NAME,\n",
    "    cache_dir=DATA_CACHE,\n",
    "    label2idx=label2idx,\n",
    "    text_label='sample',\n",
    "    target_label='annotation',\n",
    "    dtype_input_ids=dtype_input,\n",
    "    dtype_token_type_ids=dtype_input,\n",
    "    dtype_attention_mask=dtype_input,\n",
    "    dtype_labels=dtype_labels,\n",
    "    debug=True    \n",
    ")\n",
    "\n",
    "val_dataset = NerDataSet(\n",
    "    df=val_data,\n",
    "    max_length=MAX_LENGTH, \n",
    "    tokenizer_path=BASE_MODEL_NAME,\n",
    "    cache_dir=DATA_CACHE,\n",
    "    label2idx=label2idx,\n",
    "    text_label='sample',\n",
    "    target_label='annotation',\n",
    "    dtype_input_ids=dtype_input,\n",
    "    dtype_token_type_ids=dtype_input,\n",
    "    dtype_attention_mask=dtype_input,\n",
    "    dtype_labels=dtype_labels,\n",
    "    debug=True\n",
    ")\n",
    "\n",
    "test_dataset = NerDataSet(\n",
    "    df=test_data, \n",
    "    max_length=MAX_LENGTH, \n",
    "    tokenizer_path=BASE_MODEL_NAME,\n",
    "    cache_dir=DATA_CACHE,\n",
    "    label2idx=label2idx,\n",
    "    text_label='sample',\n",
    "    target_label='annotation',\n",
    "    dtype_input_ids=dtype_input,\n",
    "    dtype_token_type_ids=dtype_input,\n",
    "    dtype_attention_mask=dtype_input,\n",
    "    dtype_labels=dtype_labels,\n",
    "    debug=True\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39f90ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f0ff487",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.df.sample(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d39e8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset.plot_token_length_distribution()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26f5b27d",
   "metadata": {},
   "source": [
    "# –ú–æ–¥–µ–ª—å"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4686dab7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from typing import Optional, Tuple, List\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from transformers import BertForTokenClassification\n",
    "from transformers.utils import ModelOutput\n",
    "from torchcrf import CRF\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class TokenClassifierCRFOutput(ModelOutput):\n",
    "    \"\"\"\n",
    "    –í—ã—Ö–æ–¥ –º–æ–¥–µ–ª–∏ –¥–ª—è NER —Å CRF.\n",
    "    \"\"\"\n",
    "    loss: Optional[torch.FloatTensor] = None\n",
    "    logits: torch.FloatTensor = None  # [batch, seq_len, num_labels]\n",
    "    predictions: Optional[torch.LongTensor] = None  # [batch, seq_len] —Å –ø–∞–¥–¥–∏–Ω–≥–∞–º–∏ (-100)\n",
    "    hidden_states: Optional[Tuple[torch.FloatTensor, ...]] = None\n",
    "    attentions: Optional[Tuple[torch.FloatTensor, ...]] = None\n",
    "\n",
    "\n",
    "class BertForTokenClassificationCRF(BertForTokenClassification):\n",
    "    def __init__(self, config):\n",
    "        super().__init__(config)\n",
    "        self.classifier = nn.Linear(config.hidden_size, config.num_labels)\n",
    "        self.crf = CRF(config.num_labels, batch_first=True)\n",
    "    \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        head_mask: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> TokenClassifierCRFOutput:\n",
    "\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.bert(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]   # [batch, seq_len, hidden]\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        emissions = self.classifier(sequence_output)  # [batch, seq_len, num_labels]\n",
    "\n",
    "        loss, predictions = None, None\n",
    "        if labels is not None:\n",
    "            labels_for_crf = labels.clone()\n",
    "            labels_for_crf[labels_for_crf == -100] = 0\n",
    "\n",
    "            loss = -self.crf(\n",
    "                emissions,\n",
    "                labels_for_crf,\n",
    "                mask=attention_mask.bool(),\n",
    "                reduction=\"mean\"\n",
    "            )\n",
    "\n",
    "        decoded = self.crf.decode(emissions, mask=attention_mask.bool())\n",
    "\n",
    "        max_len = emissions.size(1)\n",
    "        predictions_padded = torch.full(\n",
    "            (len(decoded), max_len),\n",
    "            fill_value=-100,\n",
    "            dtype=torch.long,\n",
    "            device=emissions.device,\n",
    "        )\n",
    "        for i, seq in enumerate(decoded):\n",
    "            predictions_padded[i, :len(seq)] = torch.tensor(seq, dtype=torch.long, device=emissions.device)\n",
    "\n",
    "        \n",
    "        if not return_dict:\n",
    "            output = (emissions,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierCRFOutput(\n",
    "            loss=loss,\n",
    "            logits=emissions,\n",
    "            predictions=predictions_padded,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe9dc2de",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoConfig\n",
    "\n",
    "num_labels = len(label2idx)\n",
    "\n",
    "config = AutoConfig.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    num_labels=num_labels,\n",
    "    id2label=idx2label,     # —Å–ª–æ–≤–∞—Ä—å {int: str}\n",
    "    label2id=label2idx,     # —Å–ª–æ–≤–∞—Ä—å {str: int}\n",
    "    cache_dir=DATA_CACHE,\n",
    ")\n",
    "\n",
    "model = BertForTokenClassificationCRF.from_pretrained(\n",
    "    BASE_MODEL_NAME,\n",
    "    config=config,\n",
    "    ignore_mismatched_sizes=True,\n",
    ")\n",
    "\n",
    "model.gradient_checkpointing_enable()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3236b230",
   "metadata": {},
   "source": [
    "# –û–±—É—á–µ–Ω–∏–µ"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7178331",
   "metadata": {},
   "outputs": [],
   "source": [
    "from seqeval.metrics import precision_score, recall_score, f1_score, accuracy_score, classification_report\n",
    "\n",
    "def compute_metrics(eval_pred):\n",
    "    \"\"\"\n",
    "    –ú–µ—Ç—Ä–∏–∫–∏ –¥–ª—è NER (BIO-—Ä–∞–∑–º–µ—Ç–∫–∞) —Å CRF.\n",
    "    \"\"\"\n",
    "    predictions, labels = eval_pred.predictions, eval_pred.label_ids\n",
    "\n",
    "    true_labels = []\n",
    "    true_predictions = []\n",
    "\n",
    "    for pred_seq, label_seq in zip(predictions, labels):\n",
    "        seq_true = []\n",
    "        seq_pred = []\n",
    "        for p, l in zip(pred_seq, label_seq):\n",
    "            if l == -100:\n",
    "                continue\n",
    "            seq_true.append(idx2label[l])\n",
    "            seq_pred.append(idx2label[p])\n",
    "        true_labels.append(seq_true)\n",
    "        true_predictions.append(seq_pred)\n",
    "\n",
    "    # –æ—Å–Ω–æ–≤–Ω—ã–µ –º–µ—Ç—Ä–∏–∫–∏\n",
    "    precision = precision_score(true_labels, true_predictions)\n",
    "    recall = recall_score(true_labels, true_predictions)\n",
    "    f1_micro = f1_score(true_labels, true_predictions, average=\"micro\")\n",
    "    f1_macro = f1_score(true_labels, true_predictions, average=\"macro\")\n",
    "    accuracy = accuracy_score(true_labels, true_predictions)\n",
    "\n",
    "    report = classification_report(true_labels, true_predictions, digits=4)\n",
    "\n",
    "    metrics = {\n",
    "        \"precision\": precision,\n",
    "        \"recall\": recall,\n",
    "        \"f1_micro\": f1_micro,\n",
    "        \"f1_macro\": f1_macro,\n",
    "        \"accuracy\": accuracy,\n",
    "        \"report\": report,\n",
    "    }\n",
    "    return metrics\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "115feb94",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "from transformers import Trainer\n",
    "\n",
    "class CustomBaseTrainer(Trainer):\n",
    "    \"\"\"\n",
    "    –ö–∞—Å—Ç–æ–º–Ω—ã–π Trainer, –Ω–∞—Å–ª–µ–¥—É–µ–º—ã–π –æ—Ç transformers.Trainer.\n",
    "    https://hf.qhduan.com/docs/transformers/trainer\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, model, args, **kwargs):\n",
    "        super().__init__(model, args, **kwargs)\n",
    "\n",
    "    def plot_results(self):\n",
    "        \"\"\"\n",
    "        –ì—Ä–∞—Ñ–∏–∫–∏ –ø–æ—Ç–µ—Ä—å –∏ –º–µ—Ç—Ä–∏–∫ –Ω–∞ –æ—Å–Ω–æ–≤–µ `trainer.state.log_history`.\n",
    "\n",
    "        –ì—Ä–∞—Ñ–∏–∫–∏ —Å—Ç—Ä–æ—è—Ç—Å—è –¥–ª—è:\n",
    "        - `loss` (–ø–æ—Ç–µ—Ä–∏ –Ω–∞ –æ–±—É—á–µ–Ω–∏–∏)\n",
    "        - `eval_loss` (–ø–æ—Ç–µ—Ä–∏ –Ω–∞ –≤–∞–ª–∏–¥–∞—Ü–∏–∏)\n",
    "        - `eval_accuracy`, `eval_f1`, `eval_f1_macro` (–µ—Å–ª–∏ –æ–Ω–∏ –±—ã–ª–∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω—ã)\n",
    "        \"\"\"\n",
    "\n",
    "        if not self.state.log_history:\n",
    "            print(\"–ù–µ—Ç –¥–∞–Ω–Ω—ã—Ö –¥–ª—è –ø–æ—Å—Ç—Ä–æ–µ–Ω–∏—è –≥—Ä–∞—Ñ–∏–∫–æ–≤. –ü—Ä–æ–≤–µ—Ä—å—Ç–µ, –≤—ã–ø–æ–ª–Ω—è–ª–æ—Å—å –ª–∏ –æ–±—É—á–µ–Ω–∏–µ.\")\n",
    "            return\n",
    "        \n",
    "        # –ó–∞–≥—Ä—É–∂–∞–µ–º –∏—Å—Ç–æ—Ä–∏—é –ª–æ–≥–æ–≤ –≤ DataFrame\n",
    "        log_data = pd.DataFrame(self.state.log_history)\n",
    "\n",
    "        # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å —ç–ø–æ—Ö–∞–º–∏\n",
    "        log_data = log_data.dropna(subset=[\"epoch\"])  # –û—Å—Ç–∞–≤–ª—è–µ–º —Ç–æ–ª—å–∫–æ —Å—Ç—Ä–æ–∫–∏ —Å —ç–ø–æ—Ö–∞–º–∏\n",
    "        log_data = log_data.groupby(\"epoch\").last().reset_index()  # –£–±–∏—Ä–∞–µ–º –¥—É–±–ª–∏ –ø–æ —ç–ø–æ—Ö–∞–º\n",
    "        \n",
    "        # –°–ø–∏—Å–æ–∫ –º–µ—Ç—Ä–∏–∫, –∫–æ—Ç–æ—Ä—ã–µ –º–æ–∂–Ω–æ –æ—Ç–æ–±—Ä–∞–∑–∏—Ç—å\n",
    "        available_metrics = [col for col in log_data.columns if col.startswith(\"eval_\") or col == \"loss\"]\n",
    "\n",
    "        # –û–ø—Ä–µ–¥–µ–ª—è–µ–º –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ –≥—Ä–∞—Ñ–∏–∫–æ–≤\n",
    "        num_plots = len(available_metrics)\n",
    "        plt.figure(figsize=(8, 4 * num_plots))\n",
    "\n",
    "        for i, metric in enumerate(available_metrics, start=1):\n",
    "            plt.subplot(num_plots, 1, i)\n",
    "            plt.plot(log_data[\"epoch\"], log_data[metric], marker=\"o\", label=metric)\n",
    "\n",
    "            plt.xlabel(\"–≠–ø–æ—Ö–∏\")\n",
    "            plt.ylabel(metric)\n",
    "            plt.title(f\"–ì—Ä–∞—Ñ–∏–∫ {metric}\")\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "\n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ec50deb",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments\n",
    "\n",
    "training_args = TrainingArguments(\n",
    "    # üü¢ –û–±—â–∏–µ –ø–∞—Ä–∞–º–µ—Ç—Ä—ã —Ç—Ä–µ–Ω–∏—Ä–æ–≤–∫–∏\n",
    "    output_dir=DATA_PATH_SAVE_MODELS / MODEL_CHECKPOINT_PATH,  # –ü–∞–ø–∫–∞ –¥–ª—è —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∏—è –º–æ–¥–µ–ª–µ–π\n",
    "    # learning_rate=1e-4,  # –°–∫–æ—Ä–æ—Å—Ç—å –æ–±—É—á–µ–Ω–∏—è\n",
    "    num_train_epochs=10,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ —ç–ø–æ—Ö\n",
    "    # weight_decay=1e-2,  # L2-—Ä–µ–≥—É–ª—è—Ä–∏–∑–∞—Ü–∏—è\n",
    "    # optim=\"adamw_torch\",  # –û–ø—Ç–∏–º–∏–∑–∞—Ç–æ—Ä AdamW\n",
    "    # lr_scheduler_type=\"cosine\",\n",
    "    # warmup_ratio=0.1,\n",
    "\n",
    "    # üîµ –û—Ü–µ–Ω–∫–∞ –∏ –ª–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ\n",
    "    eval_strategy=\"steps\",  # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n",
    "    eval_steps=100,  # –û—Ü–µ–Ω–∫–∞ –º–æ–¥–µ–ª–∏ –∫–∞–∂–¥—ã–π —à–∞–≥\n",
    "    logging_strategy=\"steps\",  # –õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –∫–∞–∂–¥—ã–µ N —à–∞–≥–æ–≤\n",
    "    logging_steps=100,  # –ö–∞–∫ —á–∞—Å—Ç–æ –ª–æ–≥–∏—Ä–æ–≤–∞—Ç—å\n",
    "    disable_tqdm=False,  # –û—Ç–∫–ª—é—á–∏—Ç—å tqdm (–Ω—É–∂–Ω–æ –¥–ª—è —Ä–∞–±–æ—Ç—ã –≤ Colab/Kaggle)\n",
    "    report_to=\"tensorboard\",  # –õ–æ–≥–∏—Ä—É–µ–º –≤ TensorBoard\n",
    "    logging_dir=DATA_LOG,  # –ü–∞–ø–∫–∞ –¥–ª—è –ª–æ–≥–æ–≤\n",
    "\n",
    "    # üü† –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–µ–π\n",
    "    save_strategy=\"steps\",  # –°–æ—Ö—Ä–∞–Ω–µ–Ω–∏–µ –º–æ–¥–µ–ª–∏ –ø–æ—Å–ª–µ –∫–∞–∂–¥–æ–π —ç–ø–æ—Ö–∏\n",
    "    save_steps=100, # –ï—Å–ª–∏ save_strategy=\"steps\"\n",
    "    save_total_limit=5,  # –•—Ä–∞–Ω–∏–º –≤—Å–µ\n",
    "    load_best_model_at_end=True,  # –ó–∞–≥—Ä—É–∂–∞—Ç—å –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ—Å–ª–µ –æ–±—É—á–µ–Ω–∏—è\n",
    "    metric_for_best_model=\"eval_f1_macro\",  # –í—ã–±–∏—Ä–∞–µ–º –ª—É—á—à—É—é –º–æ–¥–µ–ª—å –ø–æ eval_f1_macro\n",
    "    greater_is_better=True,  # –ß–µ–º –º–µ–Ω—å—à–µ eval_loss, —Ç–µ–º –ª—É—á—à–µ –º–æ–¥–µ–ª—å\n",
    "\n",
    "    # üî¥ –ü–æ–¥–¥–µ—Ä–∂–∫–∞ –≤–æ–∑–æ–±–Ω–æ–≤–ª–µ–Ω–∏—è –æ–±—É—á–µ–Ω–∏—è\n",
    "    # save_steps=500,  # –°–æ—Ö—Ä–∞–Ω—è—Ç—å –∫–∞–∂–¥—ã–µ 500 —à–∞–≥–æ–≤ (–Ω–∞ —Å–ª—É—á–∞–π –¥–æ–ª–≥–∏—Ö —ç–ø–æ—Ö)\n",
    "    # resume_from_checkpoint=True,  # –ê–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –ø—Ä–æ–¥–æ–ª–∂–∞—Ç—å –æ–±—É—á–µ–Ω–∏–µ —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —á–µ–∫–ø–æ–∏–Ω—Ç–∞\n",
    "    # trainer.train(resume_from_checkpoint=\"./saved_model/checkpoint-1500\")\n",
    "\n",
    "    # üü° –ü–∞—Ä–∞–º–µ—Ç—Ä—ã –æ–±—É—á–µ–Ω–∏—è (batch_size, precision, –≥—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ)\n",
    "    per_device_train_batch_size=BATCH_SIZE,  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –Ω–∞ –æ–¥–Ω–æ —É—Å—Ç—Ä–æ–π—Å—Ç–≤–æ (GPU/CPU)\n",
    "    per_device_eval_batch_size=BATCH_SIZE,  # –†–∞–∑–º–µ—Ä –±–∞—Ç—á–∞ –¥–ª—è –≤–∞–ª–∏–¥–∞—Ü–∏–∏\n",
    "    # gradient_accumulation_steps=4,  # –ì—Ä–∞–¥–∏–µ–Ω—Ç–Ω–æ–µ –Ω–∞–∫–æ–ø–ª–µ–Ω–∏–µ (—Å–∏–º—É–ª–∏—Ä—É–µ—Ç batch_size –≤ 4 —Ä–∞–∑–∞ –±–æ–ª—å—à–µ)\n",
    "    # fp16=True,  # –í–∫–ª—é—á–∏—Ç—å mixed precision (—É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ –Ω–∞ GPU)\n",
    "\n",
    "    # # üîµ –û–ø—Ç–∏–º–∏–∑–∞—Ü–∏—è —Å–∫–æ—Ä–æ—Å—Ç–∏ (—É—Å–∫–æ—Ä–µ–Ω–∏–µ –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö)\n",
    "    # group_by_length=True,  # –î–∏–Ω–∞–º–∏—á–µ—Å–∫–æ–µ –∏–∑–º–µ–Ω–µ–Ω–∏–µ batch_size (—É—Å–∫–æ—Ä—è–µ—Ç –æ–±—É—á–µ–Ω–∏–µ)\n",
    "    # dataloader_num_workers=4,  # –ö–æ–ª–∏—á–µ—Å—Ç–≤–æ –ø–æ—Ç–æ–∫–æ–≤ –¥–ª—è –∑–∞–≥—Ä—É–∑–∫–∏ –¥–∞–Ω–Ω—ã—Ö\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f31cc7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_cosine_schedule_with_warmup\n",
    "\n",
    "optimizer = torch.optim.AdamW(model.parameters(), lr=1e-5, weight_decay=1e-2)\n",
    "\n",
    "steps_per_epoch = len(train_dataset.df) // training_args.per_device_train_batch_size\n",
    "total_steps = steps_per_epoch * training_args.num_train_epochs\n",
    "\n",
    "scheduler = get_cosine_schedule_with_warmup(\n",
    "    optimizer,\n",
    "    num_warmup_steps=int(0.2 * total_steps),    # 20% —à–∞–≥–æ–≤ –Ω–∞ —Ä–∞–∑–æ–≥—Ä–µ–≤\n",
    "    num_training_steps=total_steps              # –ø–æ–ª–Ω—ã–π —Ü–∏–∫–ª –∫–æ—Å–∏–Ω—É—Å–Ω–æ–≥–æ –∑–∞—Ç—É—Ö–∞–Ω–∏—è\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03d2cfaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_logits_for_metrics(logits, labels):\n",
    "    if isinstance(logits, tuple):\n",
    "        logits = logits[0]\n",
    "    return torch.argmax(logits, dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68fbdea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer = CustomBaseTrainer(\n",
    "    model=model,\n",
    "    args=training_args,\n",
    "    train_dataset=train_dataset,\n",
    "    eval_dataset=val_dataset,\n",
    "    optimizers=(optimizer, scheduler),\n",
    "    compute_metrics=compute_metrics,\n",
    "    processing_class=train_dataset.tokenizer,\n",
    "    preprocess_logits_for_metrics=preprocess_logits_for_metrics\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0de557",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9acce5c",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33452675",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.plot_results()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25824222",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_results = trainer.predict(test_dataset)\n",
    "print(test_results.metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b28b04",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.save_model(DATA_PATH_SAVE_MODELS / MODEL_NAME_SAVE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a303d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "AutoModelForSequenceClassification.from_pretrained(DATA_PATH_SAVE_MODELS / MODEL_NAME_SAVE)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
