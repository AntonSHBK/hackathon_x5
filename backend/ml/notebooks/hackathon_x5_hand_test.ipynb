{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cce5d94a",
   "metadata": {},
   "source": [
    "# X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "837ebf48",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import torch\n",
    "\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "def seed_all(seed: int) -> None:\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "    random.seed(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "36e0b595",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42\n",
    "# seed_all(SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fa85f0e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch.cuda.reset_peak_memory_stats()\n",
    "# torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ed2f6b4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "DATA_PATH = Path('../../../data/')\n",
    "DATA_PATH.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_DOWNLOAD = DATA_PATH / Path('download/')\n",
    "DATA_PATH_DOWNLOAD.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_DATASET = DATA_PATH / Path('datasets/')\n",
    "DATA_PATH_DATASET.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_SYNTHETICS = DATA_PATH / Path('synthetics/')\n",
    "DATA_PATH_DATASET.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_CACHE = DATA_PATH / Path('cache_dir/')\n",
    "DATA_CACHE.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_PATH_SAVE_MODELS = DATA_PATH / Path('models/')\n",
    "DATA_PATH_SAVE_MODELS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "DATA_IMGS = DATA_PATH /  Path('imgs/')\n",
    "DATA_IMGS.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "pd.set_option('display.max_colwidth', 500) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d7fcec7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "\n",
    "project_path = os.path.abspath(os.path.join(os.getcwd(), \"../../\"))\n",
    "sys.path.append(project_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "5a7fed11",
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f5d6a98",
   "metadata": {},
   "source": [
    "# Ручное тестирование"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a303d9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "\n",
    "from ml.pipline import NERPipelineCRF\n",
    "\n",
    "model_dir = DATA_PATH_SAVE_MODELS / \"ner_x5\"\n",
    "label2idx_path = DATA_PATH_SAVE_MODELS / \"label2idx.json\"\n",
    "idx2label_path = DATA_PATH_SAVE_MODELS / \"idx2label.json\"\n",
    "\n",
    "with open(label2idx_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    label2idx = json.load(f)\n",
    "\n",
    "with open(idx2label_path, \"r\", encoding=\"utf-8\") as f:\n",
    "    idx2label = {int(k): v for k, v in json.load(f).items()}\n",
    "\n",
    "pipeline = NERPipelineCRF(\n",
    "    model_path=model_dir,\n",
    "    label2idx=label2idx,\n",
    "    idx2label=idx2label,\n",
    "    max_length=16\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3670b02f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Текст: йогурт данисимо фантазия\n",
      "[{'start_index': 0, 'end_index': 6, 'entity': 'B-TYPE', 'word': 'йогурт'}, {'start_index': 7, 'end_index': 15, 'entity': 'B-BRAND', 'word': 'данисимо'}, {'start_index': 16, 'end_index': 24, 'entity': 'I-BRAND', 'word': 'фантазия'}]\n",
      "Текст: молоко простоквашино 3.2% 930г\n",
      "[{'start_index': 0, 'end_index': 6, 'entity': 'B-TYPE', 'word': 'молоко'}, {'start_index': 7, 'end_index': 20, 'entity': 'B-BRAND', 'word': 'простоквашино'}, {'start_index': 21, 'end_index': 25, 'entity': 'B-PERCENT', 'word': '3.2%'}, {'start_index': 26, 'end_index': 30, 'entity': 'I-PERCENT', 'word': '930г'}]\n",
      "Текст: хлеб бородинский нарезка 300г\n",
      "[{'start_index': 0, 'end_index': 4, 'entity': 'B-TYPE', 'word': 'хлеб'}, {'start_index': 5, 'end_index': 16, 'entity': 'I-TYPE', 'word': 'бородинский'}, {'start_index': 17, 'end_index': 24, 'entity': 'I-TYPE', 'word': 'нарезка'}, {'start_index': 25, 'end_index': 29, 'entity': 'B-VOLUME', 'word': '300г'}]\n",
      "Текст: мороженнае как бы его взтять\n",
      "[{'start_index': 0, 'end_index': 10, 'entity': 'B-TYPE', 'word': 'мороженнае'}, {'start_index': 11, 'end_index': 14, 'entity': 'O', 'word': 'как'}, {'start_index': 15, 'end_index': 17, 'entity': 'O', 'word': 'бы'}, {'start_index': 18, 'end_index': 21, 'entity': 'O', 'word': 'его'}, {'start_index': 22, 'end_index': 28, 'entity': 'O', 'word': 'взтять'}]\n",
      "Текст: молоко⁷ цельное\n",
      "[{'start_index': 8, 'end_index': 15, 'entity': 'I-TYPE', 'word': 'цельное'}]\n",
      "Текст: паштет для кошки\n",
      "[{'start_index': 0, 'end_index': 6, 'entity': 'B-TYPE', 'word': 'паштет'}, {'start_index': 7, 'end_index': 10, 'entity': 'I-TYPE', 'word': 'для'}, {'start_index': 11, 'end_index': 16, 'entity': 'I-TYPE', 'word': 'кошки'}]\n",
      "Текст: погремушки fisher-pri\n",
      "[{'start_index': 0, 'end_index': 10, 'entity': 'B-TYPE', 'word': 'погремушки'}, {'start_index': 11, 'end_index': 21, 'entity': 'B-BRAND', 'word': 'fisher-pri'}]\n",
      "Текст: сырокопченая-колбаск\n",
      "[{'start_index': 0, 'end_index': 20, 'entity': 'B-TYPE', 'word': 'сырокопченая-колбаск'}]\n",
      "Текст: мясное пюре для пупсов\n",
      "[{'start_index': 0, 'end_index': 6, 'entity': 'B-TYPE', 'word': 'мясное'}, {'start_index': 7, 'end_index': 11, 'entity': 'I-TYPE', 'word': 'пюре'}, {'start_index': 12, 'end_index': 15, 'entity': 'I-TYPE', 'word': 'для'}, {'start_index': 16, 'end_index': 22, 'entity': 'I-TYPE', 'word': 'пупсов'}]\n",
      "Текст: гримы, гуммо\n",
      "[{'start_index': 0, 'end_index': 6, 'entity': 'B-TYPE', 'word': 'гримы,'}, {'start_index': 7, 'end_index': 12, 'entity': 'I-TYPE', 'word': 'гуммо'}]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\Projects\\hackathon_x5\\backend\\ml\\pipline.py:79: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\torch\\csrc\\utils\\tensor_new.cpp:256.)\n",
      "  \"offset_mapping\": torch.tensor([offsets])\n"
     ]
    }
   ],
   "source": [
    "text = [\n",
    "    \"йогурт данисимо фантазия\",\n",
    "    \"молоко простоквашино 3.2% 930г\",\n",
    "    \"хлеб бородинский нарезка 300г\",\n",
    "    \"мороженнае как бы его взтять\",\n",
    "    \"молоко⁷ цельное\",\n",
    "    \"паштет для кошки\",\n",
    "    \"погремушки fisher-pri\",   \n",
    "    \"сырокопченая-колбаск\",\n",
    "    \"мясное пюре для пупсов\",\n",
    "    \"гримы, гуммо\"\n",
    "]\n",
    "entities = pipeline.predict(text, return_word=True)\n",
    "\n",
    "for i, entity in enumerate(entities):\n",
    "    print(f\"Текст: {text[i]}\")\n",
    "    print(entity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "80260521",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "def run_inference_on_dataframe(\n",
    "    pipeline, \n",
    "    df: pd.DataFrame,\n",
    "    text_col: str = \"sample\", \n",
    "    batch_size: int = 64\n",
    ") -> pd.DataFrame:\n",
    "    \n",
    "    texts = df[text_col].tolist()\n",
    "    all_entities = []\n",
    "\n",
    "    for i in tqdm(range(0, len(texts), batch_size), desc=\"Running inference\", ncols=100):\n",
    "        batch_texts = texts[i:i+batch_size]\n",
    "        batch_entities = pipeline.predict(batch_texts, batch_size=batch_size)\n",
    "        all_entities.extend(batch_entities)\n",
    "\n",
    "    formatted_entities = [\n",
    "        [(ent[\"start_index\"], ent[\"end_index\"], ent[\"entity\"]) for ent in ents]\n",
    "        for ents in all_entities\n",
    "    ]\n",
    "\n",
    "    df_result = pd.DataFrame({\n",
    "        \"id\": range(1, len(texts) + 1),\n",
    "        \"search_query\": texts,\n",
    "        \"annotation\": formatted_entities\n",
    "    })\n",
    "\n",
    "    return df_result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9a6f5ace",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_annotations(ann_list):\n",
    "    if isinstance(ann_list, str):\n",
    "        ann_list = eval(ann_list)\n",
    "    new_list = []\n",
    "    for start, end, label in ann_list:\n",
    "        if label == \"0\":\n",
    "            label = \"O\"\n",
    "        new_list.append((start, end, label))\n",
    "    return new_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "adfc4c34",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_submission = pd.read_csv(DATA_PATH_DATASET / \"submission.csv\", sep=\";\")\n",
    "df_submission[\"annotation\"] = df_submission[\"annotation\"].apply(normalize_annotations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "2d7e89c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Running inference: 100%|████████████████████████████████████████████| 79/79 [00:06<00:00, 11.48it/s]\n"
     ]
    }
   ],
   "source": [
    "df_result = run_inference_on_dataframe(pipeline, df_submission, text_col=\"sample\", batch_size=64)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4858d928",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>search_query</th>\n",
       "      <th>annotation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4175</th>\n",
       "      <td>4176</td>\n",
       "      <td>сыр на пиццу</td>\n",
       "      <td>[(0, 3, B-TYPE), (4, 6, I-TYPE), (7, 12, I-TYPE)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3285</th>\n",
       "      <td>3286</td>\n",
       "      <td>lipton</td>\n",
       "      <td>[(0, 6, B-BRAND)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3572</th>\n",
       "      <td>3573</td>\n",
       "      <td>мешки для мусора 120 л</td>\n",
       "      <td>[(0, 5, B-TYPE), (6, 9, O), (10, 16, O), (17, 20, O), (21, 22, O)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2074</th>\n",
       "      <td>2075</td>\n",
       "      <td>компоты агрокомплекс</td>\n",
       "      <td>[(0, 7, B-TYPE), (8, 20, B-BRAND)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2726</th>\n",
       "      <td>2727</td>\n",
       "      <td>соломк</td>\n",
       "      <td>[(0, 6, B-TYPE)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        id            search_query  \\\n",
       "4175  4176            сыр на пиццу   \n",
       "3285  3286                  lipton   \n",
       "3572  3573  мешки для мусора 120 л   \n",
       "2074  2075    компоты агрокомплекс   \n",
       "2726  2727                  соломк   \n",
       "\n",
       "                                                              annotation  \n",
       "4175                   [(0, 3, B-TYPE), (4, 6, I-TYPE), (7, 12, I-TYPE)]  \n",
       "3285                                                   [(0, 6, B-BRAND)]  \n",
       "3572  [(0, 5, B-TYPE), (6, 9, O), (10, 16, O), (17, 20, O), (21, 22, O)]  \n",
       "2074                                  [(0, 7, B-TYPE), (8, 20, B-BRAND)]  \n",
       "2726                                                    [(0, 6, B-TYPE)]  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_result.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "09516199",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.to_csv(DATA_PATH_DOWNLOAD /  \"submission.csv\", index=False, sep=\";\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
