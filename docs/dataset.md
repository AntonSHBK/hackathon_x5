# Класс для датасета

Для подготовки данных к обучению и инференсу был создан класс **`NerDataSet`**, наследующий стандартный PyTorch-класс `Dataset`. Его задача — превратить исходные данные (тексты и аннотации) в формат, который можно подать на вход модели.

На этапе инициализации класс принимает датафрейм с текстами и разметкой, токенизатор и словарь меток. Тексты токенизируются с помощью fast-токенизатора HuggingFace. При этом дополнительно возвращается `offset_mapping`, который позволяет сопоставить позиции токенов с исходными символами в тексте. Это необходимо для правильного переноса BIO-разметки на уровень частиц слов.

Для каждого текста формируется список меток. Алгоритм назначает токенам соответствующие метки в BIO-формате: первый токен сущности получает метку `B-XXX`, последующие — `I-XXX`. Если токен попадает в паддинг, ему присваивается значение `-100`, чтобы модель игнорировала его при расчёте функции потерь. В результате формируются четыре массива: `input_ids`, `token_type_ids`, `attention_mask` и `labels`, которые сохраняются в виде тензоров PyTorch.

Класс также поддерживает режим **debug**, при котором сохраняются вспомогательные данные: идентификаторы токенов, их текстовое представление и метки. Это удобно для проверки корректности токенизации и BIO-разметки.

Кроме основной функции подготовки данных, `NerDataSet` содержит дополнительные методы:

* `plot_token_length_distribution` — строит распределение длин токенизированных текстов, что позволяет подобрать оптимальное значение `max_length`;
* `prepare_text` — подготавливает отдельный текст для инференса, возвращая необходимые тензоры;
* `decode_predictions` — преобразует предсказанные моделью метки обратно в список сущностей с координатами начала и конца в исходной строке. При этом части слов одного слова объединяются, а разные слова той же сущности корректно маркируются в формате BIO.