### Процесс обучения модели

#### 1. Базовый тренер

Для организации обучения использовался встроенный класс `Trainer` из библиотеки HuggingFace. На его основе был реализован собственный класс `CustomBaseTrainer`, куда была добавлена функция визуализации динамики обучения. Логи, сохраняемые во время процесса, конвертировались в таблицу и далее отображались в виде графиков: изменение функции потерь, динамика precision, recall и F1-score по эпохам.

#### 2. Конфигурация параметров

Параметры обучения задавались через объект `TrainingArguments`. В проекте были выбраны следующие настройки:

* **Количество эпох**: 20 — подобранное значение позволило достичь сходимости без явного переобучения.
* **Размер батча**: 16 (одинаковый для обучения и валидации), что обеспечило баланс между скоростью обучения и стабильностью градиентов.
* **Стратегия оценки**: модель оценивалась каждые 200 шагов (`eval_steps=200`), что позволяло оперативно проверять метрики без чрезмерных вычислительных затрат.
* **Стратегия сохранения**: аналогично каждые 200 шагов сохранялась версия модели, при этом хранилось не более 5 последних чекпоинтов, что ограничивало расход памяти.
* **Метрика для выбора лучшей модели**: F1-macro, так как этот показатель отражает сбалансированное качество работы по всем классам.
* **Логирование**: каждые 200 шагов результаты отправлялись в TensorBoard, дополнительно сохранялись в указанную директорию.
* **Опция загрузки лучшей модели**: по завершении обучения автоматически загружалась версия модели с максимальным значением F1-macro.

#### 3. Оптимизация и шедулер

В качестве оптимизатора применялся **AdamW** с начальными параметрами:

* скорость обучения `lr=1e-5`,
* коэффициент weight decay `1e-2`.

Для управления скоростью обучения использовался **косинусный шедулер с разогревом**.

* Доля шагов разогрева составила 20% от общего числа,
* далее learning rate снижался по косинусной кривой до конца обучения.

Такой подход позволял сначала стабилизировать модель, а затем плавно уменьшать шаг, избегая резких колебаний качества.

#### 4. Работа с дисбалансом классов

В исходном датасете наблюдался дисбаланс: меток продолжения сущностей (I-*) значительно больше, чем меток начала (B-*). Чтобы учесть этот фактор, была рассчитана матрица весов для каждого класса на основе их частоты. Веса задавались обратно пропорционально количеству примеров каждого класса, а затем нормализовались. В дальнейшем они использовались при вычислении функции потерь.

#### 5. Функция потерь

Финальная функция потерь состояла из двух частей:

* **CRF-лосс** (основной, отражает корректность последовательностей BIO-меток),
* **Взвешенная кросс-энтропия** (компенсирует дисбаланс классов).

Обе составляющие комбинировались в одну функцию с коэффициентом α=0.7:

* 70% веса приходилось на CRF-лосс,
* 30% — на кросс-энтропию.

Такое решение позволило сохранить преимущества CRF в учёте зависимостей и при этом снизить влияние дисбаланса в обучающих данных.

#### 6. Метрики качества

Оценка модели проводилась с использованием библиотеки **seqeval**. Рассчитывались:

* **Precision** (точность),
* **Recall** (полнота),
* **F1-score (micro)** — общий результат по всем токенам,
* **F1-score (macro)** — усреднённый результат по всем классам,
* **Accuracy** (доля верно классифицированных токенов).

Дополнительно формировался полный отчёт `classification_report`, который включал precision, recall и F1 отдельно для каждого класса (например, BRAND, TYPE, VOLUME).
