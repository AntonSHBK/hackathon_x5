# Обучения модели

## 1. Базовый тренер

Для организации обучения использовался встроенный класс `Trainer` из библиотеки HuggingFace. На его основе был реализован собственный класс `CustomBaseTrainer`, куда была добавлена функция визуализации динамики обучения. Логи, сохраняемые во время процесса, конвертировались в таблицу и далее отображались в виде графиков: изменение функции потерь, динамика precision, recall и F1-score по эпохам.

## 2. Конфигурация параметров

Параметры обучения задавались через объект `TrainingArguments`. В проекте были выбраны следующие настройки:

* **Количество эпох**: 4 — подобранное значение позволило достичь сходимости без явного переобучения.
* **Размер батча**: 128.
* **Стратегия оценки**: модель оценивалась каждые 50 шагов (`eval_steps=50`).
* **Стратегия сохранения**: аналогично каждые 50 шагов сохранялась версия модели, при этом хранилось не более 5 последних чекпоинтов.
* **Метрика для выбора лучшей модели**: F1-macro.

## 3. Оптимизация и шедулер

В качестве оптимизатора применялся **AdamW** с начальными параметрами:

* скорость обучения `lr=1e-4`,
* коэффициент weight decay `1e-2`.

Для управления скоростью обучения использовался **косинусный шедулер с разогревом**.

* Доля шагов разогрева составила 10% от общего числа,
* далее learning rate снижался по косинусной кривой до конца обучения.

## 4. Работа с дисбалансом классов

В исходном датасете наблюдался дисбаланс: меток продолжения сущностей (I-*) значительно больше, чем меток начала (B-*). Чтобы учесть этот фактор, была рассчитана матрица весов для каждого класса на основе их частоты. Веса задавались обратно пропорционально количеству примеров каждого класса, а затем нормализовались. В дальнейшем они использовались при вычислении функции потерь.

## 5. Функция потерь

Финальная функция потерь состояла из двух частей:

* **CRF-лосс** (основной, отражает корректность последовательностей BIO-меток),
* **Взвешенная кросс-энтропия** (компенсирует дисбаланс классов).

Обе составляющие комбинировались в одну функцию с коэффициентом α=0.7:

* 70% веса приходилось на CRF-лосс,
* 30% — на кросс-энтропию.

## 6. Метрики качества

Оценка модели проводилась с использованием библиотеки **seqeval**. Рассчитывались:

* **Precision** (точность),
* **Recall** (полнота),
* **F1-score (micro)** — общий результат по всем токенам,
* **F1-score (macro)** — усреднённый результат по всем классам,
* **Accuracy** (доля верно классифицированных токенов).