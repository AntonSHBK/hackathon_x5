# Хакатон NER

Проект разработан в рамках хакатона, посвящённого задачам обработки естественного языка для ритейла. Основная цель — создание системы распознавания именованных сущностей (Named Entity Recognition, NER), которая может извлекать из пользовательских запросов бренды и категории товаров.

## Контекст хакатона

Современные торговые сети стремятся повысить качество взаимодействия с покупателями за счёт персонализации и понимания их запросов. Для этого требуется система, способная корректно анализировать короткие и часто неструктурированные фразы. Например:

* «купить молоко простоквашино»
* «чипсы lays и пиво балтика»
* «зубная паста colgate для детей»

Такие тексты характерны для реального поведения пользователей при поиске или голосовом вводе.

## Цель проекта

Во время хакатона команда работает над построением модели, которая способна:

* распознавать **бренды** в тексте (например, *простоквашино*, *lays*);
* выделять **типы и категории товаров** (например, *молоко*, *чипсы*);
* корректно работать с короткими, смешанными и неформальными запросами;
* поддерживать вкрапления иностранных слов, написанных латиницей.

## Основные задачи

1. Выбор и исследование моделей для русского языка (RuBERT и его аналоги).
2. Создание и использование синтетического датасета, отражающего специфику пользовательских запросов.
3. Организация процесса обучения и оценки качества моделей.
4. Сравнение разных архитектур и размеров моделей с учётом компромисса между скоростью и качеством.

## Ограничения

В рамках хакатона действуют специальные правила:

* нельзя использовать ручные словари, составленные под задачу;
* запрещено применять закрытые коммерческие NER-API;
* необходимо использовать открытые модели и датасеты, доступные всем участникам.

## Документация проекта

Подробное описание отдельных частей проекта вынесено в отдельные файлы в директории `docs`:

- [Общий пайплайн обработки и инференса](docs/pipline.md)
- [Описание данных](docs/dataset.md)  
- [Описание модели](docs/model.md)  
- [Процесс обучения](docs/train.md)  

## Запуск 

В docker-compose.yml можно указать переменные среды для 
```
MAX_LENGTH=16 # длина токена на вход
MAX_BATCH=24 # максимальный объем батча
MAX_WAIT_MS=6 # временное окно батча
WORKERS=2 # кол-во воркеров = числу vCPU
```
Далее, разворачиваем проект
```
cd docker
docker compose up --build -d
```
Файлы
```
label2idx.json
idx2label.json
```
генерируются при обучении модели в data/models/. Сама модель должна лежать в папке
```
/data/models/ner_x5_tiny_last
```
Если название отличается, изменить в *backend/app/main.py*
```
model_dir = data_dir / "ner_x5_tiny_last"
```

## API

```
POST /api/predict
body:
{"input": "йогурт даниссимо фантазия"}
```
Response:
```
[
  { "start_index": 0, "end_index": 6, "entity": "B-BRAND" }
]
```
Для теста 
```
curl -s -X POST http://127.0.0.1:8080/api/predict \
  -H "Content-Type: application/json" \
  -d '{"input":"йогурт даниссимо фантазия"}'
```